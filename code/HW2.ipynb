{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from distutils.version import LooseVersion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV and extract a few (>2) features using PCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Kaggle-Give-Me-Some-Data/cs-training.csv')\n",
    "train_data.drop('Unnamed: 0', axis=1) # delete ranks\n",
    "train_data = train_data.fillna(train_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "y_train = train_data['SeriousDlqin2yrs']\n",
    "X_train = train_data.drop('SeriousDlqin2yrs', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines for PCA & LR/SVM/Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR\n",
    "1. I build a pipeline that consists of a pca and a logisitic regression classifier sequentially.\n",
    "2. Then I apply the `GridSearchCV` to find the best hyper-parameter (here for LR is `C`). Note that I had applied 5-fold cross-validation by setting the `cv` as `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93313333 0.93306667 0.93333333 0.9336     0.93346667]\n",
      "CV accuracy: 0.933 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(PCA(n_components=4),\n",
    "                        LogisticRegression(random_state=1, solver='lbfgs'))\n",
    "\n",
    "param_lr = {'logisticregression__C': [10 ** -2, 10 ** -1, 10 ** 0, 10 ** 1, 10 ** 2]}\n",
    "gs = GridSearchCV(estimator=pipe_lr,\n",
    "                  param_grid=param_lr,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5)\n",
    "scores = cross_val_score(gs, X_train, y_train, \n",
    "                         scoring='accuracy', cv=5)\n",
    "print(scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
    "                                      np.std(scores)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For svm, I didn't employ the `cross_val_score` function as it takes me about $1300$ minutes to complete the grid search for only two values of hyperparameter `C`. Please check the following screenshot to find more details.\n",
    "\n",
    "![1](./svm_pain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331800000000001\n",
      "{'svc__C': 0.1, 'svc__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "pipe_svc = make_pipeline(PCA(n_components=4),\n",
    "                        SVC(random_state=1))\n",
    "\n",
    "param_range = [0.1, 1.0]\n",
    "\n",
    "param_grid = {'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  refit=True,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "# scores = cross_val_score(gs, X_train, y_train, \n",
    "#                          scoring='accuracy', cv=5)\n",
    "# print(scores)\n",
    "# print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
    "#                                       np.std(scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=4)),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(random_state=1))])\n",
      "0.9359\n",
      "{'decisiontreeclassifier__max_depth': 4}\n",
      "[0.9352     0.93583333 0.93563333 0.93713333 0.93613333]\n",
      "CV accuracy: 0.936 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "pipe_dt = make_pipeline(PCA(n_components=4),\n",
    "                        DecisionTreeClassifier(random_state=1))\n",
    "print(pipe_dt)\n",
    "\n",
    "param_dt = [{'decisiontreeclassifier__max_depth': [1, 2, 3, 4, 5, 6, 7, None]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_dt,\n",
    "                  param_grid=param_dt,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "scores = cross_val_score(gs, X_train, y_train, \n",
    "                         scoring='accuracy', cv=5)\n",
    "print(scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
    "                                      np.std(scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
